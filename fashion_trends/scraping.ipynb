{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pinscrape import scraper, Pinterest\n",
    "\n",
    "def using_search_engine(keyword, output_folder, images_to_download, proxies={}, number_of_workers=10):\n",
    "\n",
    "    details = scraper.scrape(keyword, output_folder, proxies, number_of_workers, images_to_download)\n",
    "    if details[\"isDownloaded\"]:\n",
    "        print(\"\\nDownloading completed !!\")\n",
    "        print(f\"\\nTotal urls found: {len(details['extracted_urls'])}\")\n",
    "        print(f\"\\nTotal images downloaded (including duplicate images): {len(details['urls_list'])}\")\n",
    "        print(details)\n",
    "    else:\n",
    "        print(\"\\nNothing to download !!\", details)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def using_pinterest_apis(keyword, output_folder, images_to_download, proxies={}, number_of_workers=20):\n",
    "\n",
    "    p = Pinterest(proxies=proxies) \n",
    "    images_url = p.search(keyword, images_to_download)\n",
    "    p.download(url_list=images_url, number_of_workers=number_of_workers, output_folder=output_folder)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Image search has failed!, 504, upstream request timeout\n"
     ]
    }
   ],
   "source": [
    "season_tuple = (\n",
    "    'Spring 2020', 'Summer 2020', 'Fall 2020', 'Autumn 2020', 'Winter 2020',\n",
    "    'Spring 2021', 'Summer 2021', 'Fall 2021', 'Autumn 2021', 'Winter 2021',\n",
    "    'Spring 2022', 'Summer 2022', 'Fall 2022', 'Autumn 2022', 'Winter 2022',\n",
    "    'Spring 2023', 'Summer 2023', 'Fall 2023', 'Autumn 2023', 'Winter 2023',\n",
    "    'Spring 2024', 'Summer 2024', 'Fall 2024', 'Autumn 2024', 'Winter 2024',\n",
    ")\n",
    "\n",
    "# Number of images to download\n",
    "images_to_download = 150\n",
    "\n",
    "# Loop through the months tuple\n",
    "for month in season_tuple:\n",
    "    keyword = f\"casual dresses women {month}\"\n",
    "    output_folder = f\"images\\{month}\"\n",
    "    using_pinterest_apis(keyword, output_folder, images_to_download)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name '_C' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[33], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mos\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpathlib\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Path\n",
      "File \u001b[1;32mc:\\Users\\djsma\\anaconda3\\Lib\\site-packages\\torch\\__init__.py:764\u001b[0m\n\u001b[0;32m    761\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m  \u001b[38;5;66;03m# If __file__ is not None the cause is unknown, so just re-raise.\u001b[39;00m\n\u001b[0;32m    763\u001b[0m __name, __obj \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m--> 764\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m __name \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mdir\u001b[39m(_C):\n\u001b[0;32m    765\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m __name[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m __name\u001b[38;5;241m.\u001b[39mendswith(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mBase\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[0;32m    766\u001b[0m         __all__\u001b[38;5;241m.\u001b[39mappend(__name)\n",
      "\u001b[1;31mNameError\u001b[0m: name '_C' is not defined"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from hashlib import md5\n",
    "from collections import defaultdict\n",
    "\n",
    "def process_folder_with_yolo(folder_path, output_path_1, output_path_2, model):\n",
    "    \"\"\"\n",
    "    Processes a folder to filter out non-portrait/selfie images using YOLOv5.\n",
    "    Args:\n",
    "        folder_path (str): Path to the folder containing images.\n",
    "        output_path_1 (str): Path to save images we need.\n",
    "        output_path_2 (str): Path to save images we don't need.\n",
    "        model: Pre-trained YOLOv5 model.\n",
    "    \"\"\"\n",
    "    # Create output folders if they don't exist\n",
    "    os.makedirs(output_path_1, exist_ok=True)\n",
    "    os.makedirs(output_path_2, exist_ok=True)\n",
    "\n",
    "    # Iterate through all files in the folder\n",
    "    for file_name in os.listdir(folder_path):\n",
    "        file_path = os.path.join(folder_path, file_name)\n",
    "\n",
    "        # Check if the file is an image\n",
    "        if file_name.lower().endswith(('.jpg', '.jpeg', '.png')):\n",
    "            # Run YOLOv5 model inference\n",
    "            results = model(file_path)\n",
    "            detections = results.pandas().xyxy[0]  # Get detections as a DataFrame\n",
    "\n",
    "            # Filter detections for 'person' class\n",
    "            people = detections[detections['name'] == 'person']\n",
    "\n",
    "            # Save to appropriate folder based on detection\n",
    "            if len(people) > 0:\n",
    "                output_file_path = os.path.join(output_path_1, file_name)\n",
    "            else:\n",
    "                output_file_path = os.path.join(output_path_2, file_name)\n",
    "\n",
    "            # Save the image\n",
    "            os.rename(file_path, output_file_path)\n",
    "\n",
    "def remove_seasonal_duplicates(base_path, season_tuple):\n",
    "    \"\"\"\n",
    "    Removes duplicate images across the same season by comparing file hashes.\n",
    "    Args:\n",
    "        base_path (str): Path to the base directory containing season folders.\n",
    "        season_tuple (tuple): List of all subfolder names.\n",
    "    \"\"\"\n",
    "    duplicates_count = 0\n",
    "    season_groups = defaultdict(list)\n",
    "\n",
    "    # Group folders by season (e.g., 'Fall', 'Spring')\n",
    "    for folder_name in season_tuple:\n",
    "        season = folder_name.split()[0]  # Extract the season (e.g., 'Spring', 'Fall')\n",
    "        season_groups[season].append(folder_name)\n",
    "\n",
    "    for season, folders in season_groups.items():\n",
    "        print(f\"Checking for duplicates within season: {season}\")\n",
    "        image_hashes = {}\n",
    "\n",
    "        for folder_name in folders:\n",
    "            folder_path = os.path.join(base_path, folder_name)\n",
    "\n",
    "            if os.path.exists(folder_path):\n",
    "                for file_name in os.listdir(folder_path):\n",
    "                    file_path = os.path.join(folder_path, file_name)\n",
    "\n",
    "                    if file_name.lower().endswith(('.jpg', '.jpeg', '.png')):\n",
    "                        with open(file_path, 'rb') as f:\n",
    "                            file_hash = md5(f.read()).hexdigest()\n",
    "\n",
    "                        if file_hash in image_hashes:\n",
    "                            print(f\"Duplicate found: {file_path} matches {image_hashes[file_hash]}. Removing.\")\n",
    "                            os.remove(file_path)\n",
    "                            duplicates_count += 1\n",
    "                            # Log duplicate removal\n",
    "                            print(f\"Duplicate count updated: {duplicates_count}\")\n",
    "                        else:\n",
    "                            image_hashes[file_hash] = file_path\n",
    "\n",
    "    return duplicates_count\n",
    "\n",
    "def process_all_folders(base_path, season_tuple, images_1_path, images_2_path, model):\n",
    "    \"\"\"\n",
    "    Processes all folders in season_tuple.\n",
    "    Args:\n",
    "        base_path (str): Path to the base directory containing folders.\n",
    "        season_tuple (tuple): List of all subfolder names.\n",
    "        images_1_path (str): Path to the output directory for images_1.\n",
    "        images_2_path (str): Path to the output directory for images_2.\n",
    "        model: Pre-trained YOLOv5 model.\n",
    "    \"\"\"\n",
    "    for folder_name in season_tuple:\n",
    "        folder_path = os.path.join(base_path, folder_name)\n",
    "\n",
    "        if os.path.exists(folder_path):\n",
    "            print(f\"Processing folder: {folder_name}\")\n",
    "            output_path_1 = os.path.join(images_1_path, folder_name)\n",
    "            output_path_2 = os.path.join(images_2_path, folder_name)\n",
    "            process_folder_with_yolo(folder_path, output_path_1, output_path_2, model)\n",
    "\n",
    "def calculate_distribution(base_path, season_tuple, images_1_path, images_2_path, duplicates_count):\n",
    "    \"\"\"\n",
    "    Calculates the distribution of images across all folders.\n",
    "    Args:\n",
    "        base_path (str): Path to the base directory containing folders.\n",
    "        season_tuple (tuple): List of all subfolder names.\n",
    "        images_1_path (str): Path to the output directory for images_1.\n",
    "        images_2_path (str): Path to the output directory for images_2.\n",
    "        duplicates_count (int): Number of duplicate images removed.\n",
    "    \"\"\"\n",
    "    distribution = []\n",
    "\n",
    "    for folder_name in season_tuple:\n",
    "        images_1_folder = os.path.join(images_1_path, folder_name)\n",
    "        images_2_folder = os.path.join(images_2_path, folder_name)\n",
    "\n",
    "        images_1_count = len(os.listdir(images_1_folder)) if os.path.exists(images_1_folder) else 0\n",
    "        images_2_count = len(os.listdir(images_2_folder)) if os.path.exists(images_2_folder) else 0\n",
    "\n",
    "        distribution.append({\n",
    "            \"Folder\": folder_name,\n",
    "            \"Images_1\": images_1_count,\n",
    "            \"Images_2\": images_2_count,\n",
    "            \"Total\": images_1_count + images_2_count\n",
    "        })\n",
    "\n",
    "    total_images_1 = sum(d[\"Images_1\"] for d in distribution)\n",
    "    total_images_2 = sum(d[\"Images_2\"] for d in distribution)\n",
    "\n",
    "    distribution.append({\n",
    "        \"Folder\": \"All Folders\",\n",
    "        \"Images_1\": total_images_1,\n",
    "        \"Images_2\": total_images_2,\n",
    "        \"Deleted Duplicates\": duplicates_count,\n",
    "        \"Total\": total_images_1 + total_images_2\n",
    "    })\n",
    "\n",
    "    df = pd.DataFrame(distribution)\n",
    "    return df\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Path to the dataset base directory\n",
    "    base_directory = \"images\"\n",
    "\n",
    "    # Path to images_1 and images_2 directories\n",
    "    images_1_directory = \"images1\"\n",
    "    images_2_directory = \"images2\"\n",
    "\n",
    "    # Tuple containing all subfolder names\n",
    "    season_tuple = (\n",
    "        'Spring 2020', 'Summer 2020', 'Fall 2020', 'Autumn 2020', 'Winter 2020',\n",
    "        'Spring 2021', 'Summer 2021', 'Fall 2021', 'Autumn 2021', 'Winter 2021',\n",
    "        'Spring 2022', 'Summer 2022', 'Fall 2022', 'Autumn 2022', 'Winter 2022',\n",
    "        'Spring 2023', 'Summer 2023', 'Fall 2023', 'Autumn 2023', 'Winter 2023',\n",
    "        'Spring 2024', 'Summer 2024', 'Fall 2024', 'Autumn 2024', 'Winter 2024',\n",
    "    )\n",
    "\n",
    "    # Remove duplicates within each season\n",
    "    duplicates_count = remove_seasonal_duplicates(base_directory, season_tuple)\n",
    "\n",
    "    # Load YOLOv5 model\n",
    "    model = torch.hub.load('ultralytics/yolov5', 'yolov5s', pretrained=True)\n",
    "\n",
    "    # Process all folders\n",
    "    process_all_folders(base_directory, season_tuple, images_1_directory, images_2_directory, model)\n",
    "    print(\"Filtering complete!\")\n",
    "\n",
    "    # Calculate and display distribution\n",
    "    distribution_df = calculate_distribution(base_directory, season_tuple, images_1_directory, images_2_directory, duplicates_count)\n",
    "    print(distribution_df)\n",
    "    distribution_df.to_csv(\"distribution.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in c:\\users\\djsma\\anaconda3\\lib\\site-packages (2.4.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\djsma\\anaconda3\\lib\\site-packages (from torch) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in c:\\users\\djsma\\anaconda3\\lib\\site-packages (from torch) (4.11.0)\n",
      "Requirement already satisfied: sympy in c:\\users\\djsma\\anaconda3\\lib\\site-packages (from torch) (1.13.1)\n",
      "Requirement already satisfied: networkx in c:\\users\\djsma\\anaconda3\\lib\\site-packages (from torch) (3.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\djsma\\anaconda3\\lib\\site-packages (from torch) (3.1.4)\n",
      "Requirement already satisfied: fsspec in c:\\users\\djsma\\anaconda3\\lib\\site-packages (from torch) (2023.10.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\djsma\\anaconda3\\lib\\site-packages (from jinja2->torch) (2.1.3)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\djsma\\anaconda3\\lib\\site-packages (from sympy->torch) (1.3.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.2 -> 24.3.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
